{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1cvcwC3aVctkbkwtjaaTXKdZ_M-GCJyMm","authorship_tag":"ABX9TyNy55JYraUxqL1qn64FZVwn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"E4OQLTEnKhJw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715272504545,"user_tz":-330,"elapsed":23166,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"a68161f0-76a2-4e0d-ff60-513a0d976bf0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into '/content/drive/MyDrive/SRGAN'...\n","remote: Enumerating objects: 113, done.\u001b[K\n","remote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (7/7), done.\u001b[K\n","remote: Total 113 (delta 2), reused 3 (delta 0), pack-reused 104\u001b[K\n","Receiving objects: 100% (113/113), 268.68 MiB | 15.79 MiB/s, done.\n","Resolving deltas: 100% (2/2), done.\n","Updating files: 100% (97/97), done.\n"]}],"source":["!git clone https://github.com/lizhuoq/SRGAN.git /content/drive/MyDrive/SRGAN"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4DUazUvQ52v","executionInfo":{"status":"error","timestamp":1715276949966,"user_tz":-330,"elapsed":5050,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"00e50f1b-ffb4-414b-ad8e-81f507ea97d3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["!pip install lpips"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVXTjWd8koL7","executionInfo":{"status":"ok","timestamp":1715278686166,"user_tz":-330,"elapsed":60153,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"1a969f80-9103-4707-eea1-9bb8aaeca14a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lpips\n","  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.17.1+cu121)\n","Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.25.2)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.11.4)\n","Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.66.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=0.4.0->lpips)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.0->lpips)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->lpips) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lpips\n","Successfully installed lpips-0.1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import torch\n","import torchvision.transforms as transforms\n","import lpips\n","\n","# Initialize LPIPS model\n","lpips_model = lpips.LPIPS(net='alex')\n","\n","# Path to directories containing HR and SR images\n","hr_dir = \"/content/drive/MyDrive/data/DIV2K_valid_HR/DIV2K_valid_HR\"\n","sr_dir = \"/content/drive/MyDrive/SRGAN/out_srf_4\"\n","\n","# Get list of filenames in both directories\n","hr_images = os.listdir(hr_dir)\n","sr_images = os.listdir(sr_dir)\n","\n","# Sort filenames to ensure correspondence\n","hr_images.sort()\n","sr_images.sort()\n","\n","# Check if number of images match\n","assert len(hr_images) == len(sr_images), \"Number of HR and SR images must match\"\n","\n","# Function to calculate PSNR\n","def calculate_psnr(hr_img, sr_img):\n","    psnr = cv2.PSNR(hr_img, sr_img)\n","    return psnr\n","\n","# Function to calculate LPIPS score\n","def calculate_lpips(hr_img, sr_img):\n","    # Convert images to PyTorch tensors\n","    transform = transforms.ToTensor()\n","    hr_tensor = transform(hr_img).unsqueeze(0)\n","    sr_tensor = transform(sr_img).unsqueeze(0)\n","\n","    # Calculate LPIPS score\n","    lpips_score = lpips_model(hr_tensor, sr_tensor).item()\n","    return lpips_score\n","\n","# Iterate over each pair of images and calculate scores\n","for hr_img_name, sr_img_name in zip(hr_images, sr_images):\n","    hr_img_path = os.path.join(hr_dir, hr_img_name)\n","    sr_img_path = os.path.join(sr_dir, sr_img_name)\n","\n","    # Read images\n","    hr_img = cv2.imread(hr_img_path)\n","    sr_img = cv2.imread(sr_img_path)\n","\n","    # Calculate PSNR\n","    psnr_score = calculate_psnr(hr_img, sr_img)\n","\n","    # Calculate LPIPS\n","    lpips_score = calculate_lpips(hr_img, sr_img)\n","\n","    # Print or save scores\n","    print(f\"Image: {hr_img_name}\")\n","    print(f\"PSNR: {psnr_score:.2f}\")\n","    print(f\"LPIPS: {lpips_score:.4f}\")\n","    print(\"-------------------------\")\n"],"metadata":{"id":"HiyWFaoQNPRn","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"error","timestamp":1715279694216,"user_tz":-330,"elapsed":1898,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"e14a3d07-f819-4b97-e063-1c72f0c5571e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n","Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n"]},{"output_type":"error","ename":"AssertionError","evalue":"Number of HR and SR images must match","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-9232a72806ce>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Check if number of images match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Number of HR and SR images must match\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Function to calculate PSNR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Number of HR and SR images must match"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import torch\n","import torchvision.transforms as transforms\n","import lpips\n","\n","# Initialize LPIPS model\n","lpips_model = lpips.LPIPS(net='alex')\n","\n","# Path to directories containing HR and SR images\n","hr_dir = \"/content/drive/MyDrive/data/DIV2K_valid_HR/DIV2K_valid_HR\"\n","sr_dir = \"/content/drive/MyDrive/SRGAN/out_srf_4x\"\n","\n","# Get list of filenames in both directories\n","hr_images = os.listdir(hr_dir)\n","sr_images = os.listdir(sr_dir)\n","\n","# Sort filenames to ensure correspondence\n","hr_images.sort()\n","sr_images.sort()\n","\n","# Check if number of images match\n","assert len(hr_images) == len(sr_images), \"Number of HR and SR images must match\"\n","\n","# Initialize variables to accumulate scores\n","total_psnr = 0.0\n","total_lpips = 0.0\n","num_images = len(hr_images)\n","\n","# Function to calculate PSNR\n","def calculate_psnr(hr_img, sr_img):\n","    psnr = cv2.PSNR(hr_img, sr_img)\n","    return psnr\n","\n","# Function to calculate LPIPS score\n","def calculate_lpips(hr_img, sr_img):\n","    # Convert images to PyTorch tensors\n","    transform = transforms.ToTensor()\n","    hr_tensor = transform(hr_img).unsqueeze(0)\n","    sr_tensor = transform(sr_img).unsqueeze(0)\n","\n","    # Calculate LPIPS score\n","    lpips_score = lpips_model(hr_tensor, sr_tensor).item()\n","    return lpips_score\n","\n","# Iterate over each pair of images and calculate scores\n","for hr_img_name, sr_img_name in zip(hr_images, sr_images):\n","    hr_img_path = os.path.join(hr_dir, hr_img_name)\n","    sr_img_path = os.path.join(sr_dir, sr_img_name)\n","\n","    # Read images\n","    hr_img = cv2.imread(hr_img_path)\n","    sr_img = cv2.imread(sr_img_path)\n","\n","    # Calculate PSNR\n","    psnr_score = calculate_psnr(hr_img, sr_img)\n","\n","    # Calculate LPIPS\n","    lpips_score = calculate_lpips(hr_img, sr_img)\n","\n","    # Accumulate scores\n","    total_psnr += psnr_score\n","    total_lpips += lpips_score\n","\n","# Calculate average scores\n","avg_psnr = total_psnr / num_images\n","avg_lpips = total_lpips / num_images\n","\n","# Print or save average scores\n","print(f\"Average PSNR: {avg_psnr:.2f}\")\n","print(f\"Average LPIPS: {avg_lpips:.4f}\")\n"],"metadata":{"id":"H5JHoP_5k9DN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715280511280,"user_tz":-330,"elapsed":141544,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"b7feafa2-0752-4a74-99a7-672d8d6f3dd2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n","Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n","Average PSNR: 17.31\n","Average LPIPS: 0.5894\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import torch\n","import torchvision.transforms as transforms\n","import lpips\n","\n","# Initialize LPIPS model\n","lpips_model = lpips.LPIPS(net='alex')\n","\n","# Path to directories containing HR and SR images\n","hr_dir = \"/content/drive/MyDrive/data/DIV2K_valid_HR/DIV2K_valid_HR\"\n","sr_dir = \"/content/drive/MyDrive/SRGAN/out_srf_4x\"\n","\n","# Get list of filenames in both directories\n","hr_images = os.listdir(hr_dir)\n","sr_images = os.listdir(sr_dir)\n","\n","# Sort filenames to ensure correspondence\n","hr_images.sort()\n","sr_images.sort()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-SspCz2woyyg","executionInfo":{"status":"ok","timestamp":1715280338874,"user_tz":-330,"elapsed":1936,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"05ebf218-6fc9-4814-ef05-2a5b32fa39e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n"]}]},{"cell_type":"code","source":["len(hr_images)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BNF_XElNpN5_","executionInfo":{"status":"ok","timestamp":1715280345724,"user_tz":-330,"elapsed":5,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"3cef4bf6-41ef-413e-dca4-a8546af2d5a2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["len(sr_images)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ewNrwF3GpUbJ","executionInfo":{"status":"ok","timestamp":1715280350884,"user_tz":-330,"elapsed":4,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"5f575bce-0ef1-4454-a854-0668ec58b43f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["import os\n","import cv2\n","import torch\n","import torchvision.transforms as transforms\n","import lpips\n","from skimage.metrics import structural_similarity as compare_ssim\n","import glob\n","\n","# Initialize LPIPS model\n","lpips_model = lpips.LPIPS(net='alex')\n","\n","# Path to directories containing HR and SR images\n","hr_dir = \"/content/drive/MyDrive/data/Set5/image_SRF_4/*_4_HR.png\"\n","sr_dir = \"/content/drive/MyDrive/ESRGAN/results/Set5_*.png\"\n","\n","# Get list of filenames in both directories\n","hr_images = glob.glob(hr_dir)\n","sr_images = glob.glob(sr_dir)\n","\n","# Sort filenames to ensure correspondence\n","hr_images.sort()\n","sr_images.sort()\n","\n","# Check if number of images match\n","assert len(hr_images) == len(sr_images), \"Number of HR and SR images must match\"\n","\n","# Initialize variables to accumulate scores\n","total_psnr = 0.0\n","total_lpips = 0.0\n","total_ssim = 0.0\n","num_images = len(hr_images)\n","\n","# Function to calculate PSNR\n","def calculate_psnr(hr_img, sr_img):\n","    psnr = cv2.PSNR(hr_img, sr_img)\n","    return psnr\n","\n","# Function to calculate LPIPS score\n","def calculate_lpips(hr_img, sr_img):\n","    # Convert images to PyTorch tensors\n","    transform = transforms.ToTensor()\n","    hr_tensor = transform(hr_img).unsqueeze(0)\n","    sr_tensor = transform(sr_img).unsqueeze(0)\n","\n","    # Calculate LPIPS score\n","    lpips_score = lpips_model(hr_tensor, sr_tensor).item()\n","    return lpips_score\n","\n","# Iterate over each pair of images and calculate scores\n","for hr_img_path, sr_img_path in zip(hr_images, sr_images):\n","    # Read images\n","    hr_img = cv2.imread(hr_img_path)\n","    sr_img = cv2.imread(sr_img_path)\n","\n","    # Calculate PSNR\n","    psnr_score = calculate_psnr(hr_img, sr_img)\n","\n","    # Calculate LPIPS\n","    lpips_score = calculate_lpips(hr_img, sr_img)\n","\n","    # Calculate SSIM\n","    ssim_score, _ = compare_ssim(hr_img, sr_img, full=True)\n","\n","    # Accumulate scores\n","    total_psnr += psnr_score\n","    total_lpips += lpips_score\n","    total_ssim += ssim_score\n","\n","# Calculate average scores\n","avg_psnr = total_psnr / num_images\n","avg_lpips = total_lpips / num_images\n","avg_ssim = total_ssim / num_images\n","\n","# Print or save average scores\n","print(f\"Average PSNR: {avg_psnr:.2f}\")\n","print(f\"Average LPIPS: {avg_lpips:.4f}\")\n","print(f\"Average SSIM: {avg_ssim:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":567},"id":"y56J_40ApWjP","executionInfo":{"status":"error","timestamp":1715359437245,"user_tz":-330,"elapsed":14179,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"6445a3a6-a774-43cb-fc34-c05009e991c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","100%|██████████| 233M/233M [00:02<00:00, 84.6MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n"]},{"output_type":"error","ename":"ValueError","evalue":"win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-1bae8712a178>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# Calculate SSIM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mssim_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Accumulate scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mfixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Call the function with the fixed arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/metrics/_structural_similarity.py\u001b[0m in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, multichannel, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;34m'win_size exceeds image extent. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;34m'Either ensure that your images are '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels."]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import torch\n","import torchvision.transforms as transforms\n","import lpips\n","import glob\n","\n","\n","# Initialize LPIPS model\n","lpips_model = lpips.LPIPS(net='alex')\n","\n","hr_dir = \"/content/drive/MyDrive/data/Set5/image_SRF_4/*_4_HR.png\"\n","sr_dir = \"/content/drive/MyDrive/ESRGAN/results/Set5_*.png\"\n","\n","# Get list of filenames in both directories\n","hr_images = glob.glob(hr_dir)\n","sr_images = glob.glob(sr_dir)\n","\n","# Sort filenames to ensure correspondence\n","hr_images.sort()\n","sr_images.sort()\n","\n","# Check if number of images match\n","assert len(hr_images) == len(sr_images), \"Number of HR and SR images must match\"\n","\n","# Initialize variables to accumulate scores\n","total_psnr = 0.0\n","total_lpips = 0.0\n","num_images = len(hr_images)\n","\n","# Function to calculate PSNR\n","def calculate_psnr(hr_img, sr_img):\n","    psnr = cv2.PSNR(hr_img, sr_img)\n","    return psnr\n","\n","# Function to calculate LPIPS score\n","def calculate_lpips(hr_img, sr_img):\n","    # Convert images to PyTorch tensors\n","    transform = transforms.ToTensor()\n","    hr_tensor = transform(hr_img).unsqueeze(0)\n","    sr_tensor = transform(sr_img).unsqueeze(0)\n","\n","    # Calculate LPIPS score\n","    lpips_score = lpips_model(hr_tensor, sr_tensor).item()\n","    return lpips_score\n","\n","# Iterate over each pair of images and calculate scores\n","for hr_img_name, sr_img_name in zip(hr_images, sr_images):\n","    hr_img_path = os.path.join(hr_dir, hr_img_name)\n","    sr_img_path = os.path.join(sr_dir, sr_img_name)\n","\n","    # Read images\n","    hr_img = cv2.imread(hr_img_path)\n","    sr_img = cv2.imread(sr_img_path)\n","\n","    # Calculate PSNR\n","    psnr_score = calculate_psnr(hr_img, sr_img)\n","\n","    # Calculate LPIPS\n","    lpips_score = calculate_lpips(hr_img, sr_img)\n","\n","    # Accumulate scores\n","    total_psnr += psnr_score\n","    total_lpips += lpips_score\n","\n","# Calculate average scores\n","avg_psnr = total_psnr / num_images\n","avg_lpips = total_lpips / num_images\n","\n","# Print or save average scores\n","print(f\"Average PSNR: {avg_psnr:.2f}\")\n","print(f\"Average LPIPS: {avg_lpips:.4f}\")\n"],"metadata":{"id":"57xubnQFqBJQ","executionInfo":{"status":"ok","timestamp":1715360401658,"user_tz":-330,"elapsed":9902,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"916d7780-cfec-4707-cc95-035317c9fad0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n","Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n","Average PSNR: 28.44\n","Average LPIPS: 0.0635\n"]}]},{"cell_type":"code","source":["!pip install lpips"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAM4i59ks--H","executionInfo":{"status":"ok","timestamp":1715360292657,"user_tz":-330,"elapsed":4214,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"21202052-418a-45f5-f9fd-9e0d71585b52"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lpips in /usr/local/lib/python3.10/dist-packages (0.1.4)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.17.1+cu121)\n","Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.25.2)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.11.4)\n","Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.66.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.0->lpips) (12.4.127)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->lpips) (1.3.0)\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import torch\n","import torchvision.transforms as transforms\n","import lpips\n","import glob\n","\n","\n","# Initialize LPIPS model\n","lpips_model = lpips.LPIPS(net='alex')\n","\n","hr_dir = \"/content/drive/MyDrive/data/BSD100_SR/image_SRF_4/*_4_HR.png\"\n","sr_dir = \"/content/drive/MyDrive/SRGAN/BSD100/*.png\"\n","# sr_dir = \"/content/drive/MyDrive/ESRGAN/results/BSD100*.png\"\n","\n","# Get list of filenames in both directories\n","hr_images = glob.glob(hr_dir)\n","sr_images = glob.glob(sr_dir)\n","\n","# Sort filenames to ensure correspondence\n","hr_images.sort()\n","sr_images.sort()\n","\n","# Check if number of images match\n","assert len(hr_images) == len(sr_images), \"Number of HR and SR images must match\"\n","\n","# Initialize variables to accumulate scores\n","total_psnr = 0.0\n","total_lpips = 0.0\n","num_images = len(hr_images)\n","\n","# Function to calculate PSNR\n","def calculate_psnr(hr_img, sr_img):\n","    psnr = cv2.PSNR(hr_img, sr_img)\n","    return psnr\n","\n","# Function to calculate LPIPS score\n","def calculate_lpips(hr_img, sr_img):\n","    # Convert images to PyTorch tensors\n","    transform = transforms.ToTensor()\n","    hr_tensor = transform(hr_img).unsqueeze(0)\n","    sr_tensor = transform(sr_img).unsqueeze(0)\n","\n","    # Calculate LPIPS score\n","    lpips_score = lpips_model(hr_tensor, sr_tensor).item()\n","    return lpips_score\n","\n","# Iterate over each pair of images and calculate scores\n","for hr_img_name, sr_img_name in zip(hr_images, sr_images):\n","    hr_img_path = os.path.join(hr_dir, hr_img_name)\n","    sr_img_path = os.path.join(sr_dir, sr_img_name)\n","\n","    # Read images\n","    hr_img = cv2.imread(hr_img_path)\n","    sr_img = cv2.imread(sr_img_path)\n","\n","    # Calculate PSNR\n","    psnr_score = calculate_psnr(hr_img, sr_img)\n","\n","    # Calculate LPIPS\n","    lpips_score = calculate_lpips(hr_img, sr_img)\n","\n","    # Accumulate scores\n","    total_psnr += psnr_score\n","    total_lpips += lpips_score\n","\n","# Calculate average scores\n","avg_psnr = total_psnr / num_images\n","avg_lpips = total_lpips / num_images\n","\n","# Print or save average scores\n","print(f\"Average PSNR: {avg_psnr:.2f}\")\n","print(f\"Average LPIPS: {avg_lpips:.4f}\")"],"metadata":{"id":"XoQMbIhPtLAM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715364907033,"user_tz":-330,"elapsed":60560,"user":{"displayName":"yorra","userId":"03516868328352147801"}},"outputId":"79ecb2fe-17ab-4f5e-c758-f2fb25cb306f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n","Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n","Average PSNR: 25.57\n","Average LPIPS: 0.2943\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Ae-RiufhmIVU"},"execution_count":null,"outputs":[]}]}